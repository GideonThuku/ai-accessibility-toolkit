# -*- coding: utf-8 -*-
"""ai-accessibility-toolkit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17P5ZH2ri4YucSB0bYUwUtHPuplkZS9dY
"""

import streamlit as st
import tensorflow as tf
from tensorflow.keras.applications import mobilenet_v2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions
from transformers import pipeline  # For the NLP Summarizer
import numpy as np
from PIL import Image
import re

# --- Helper Functions (for AI models) ---

# AI Model 1: Keras/TF Computer Vision Model (Week 2 & 5)
@st.cache_resource
def load_image_model():
    """Loads the pre-trained MobileNetV2 model."""
    # This message will only show the first time the app loads
    st.write("Cache Miss: Loading Image Model (first time only)...")
    model = mobilenet_v2.MobileNetV2(weights='imagenet')
    return model

def process_image(img_file):
    """Processes an uploaded image for the model."""
    # Open the image with PIL (Python Imaging Library)
    img = Image.open(img_file).convert('RGB')
    # Resize to the size MobileNetV2 expects
    img = img.resize((224, 224))
    # Convert image to a numpy array
    img_array = image.img_to_array(img)
    # Add a "batch" dimension
    img_array = np.expand_dims(img_array, axis=0)
    # Pre-process the image for the model
    img_array = preprocess_input(img_array)
    return img_array

def get_image_predictions(img_file):
    """Gets predictions from the MobileNetV2 model."""
    model = load_image_model()
    processed_img = process_image(img_file)
    # Get the model's predictions
    predictions = model.predict(processed_img)
    # Decode the predictions into human-readable labels
    decoded = decode_predictions(predictions, top=5)[0]
    return decoded

# AI Model 2: Hugging Face NLP Summarizer (Week 2 & 5)
@st.cache_resource
def load_summarizer_model():
    """Loads a pre-trained summarization pipeline from Hugging Face."""
    # This message will only show the first time this page is loaded
    st.write("Cache Miss: Loading Summarizer Model (first time only)...")
    # This will download the model (t5-small) the first time it's run
    summarizer = pipeline("summarization", model="t5-small", framework="pt")
    return summarizer

def summarize_text(text_input):
    """Summarizes the input text using the loaded model."""
    summarizer = load_summarizer_model()
    # Truncate text to avoid model errors on very long inputs
    # A more advanced app would "chunk" the text
    summary = summarizer(text_input[:1024], max_length=150, min_length=30, do_sample=False)
    # Return just the summary text
    return summary[0]['summary_text']

# AI Model 3: Rules-Based Ethical AI Scanner (Week 2 & 6)
def scan_inclusive_language(text):
    """Scans text for non-inclusive or ableist language."""
    # This is a simple, extendable dictionary.
    problematic_terms = {
        "crazy": "Use 'surprising' or 'wild' instead; avoids stigmatizing mental health.",
        "insane": "Use 'unbelievable' or 'chaotic'; avoids stigmatizing mental health.",
        "lame": "Use 'uninspiring' or 'disappointing'; avoids ableist language.",
        "dumb": "Use 'unhelpful' or 'simple'; avoids ableist language.",
        "blind spot": "Use 'oversight' or 'area for improvement'; avoids ableist metaphor.",
        "tone deaf": "Use 'insensitive' or 'unaware'; avoids ableist metaphor.",
        "guys": "Use 'everyone', 'team', or 'folks' for mixed-gender groups."
    }

    found = []
    # Use regex to find whole words, case-insensitive
    for term, suggestion in problematic_terms.items():
        if re.search(r'\b' + re.escape(term) + r'\b', text, re.IGNORECASE):
            found.append((term, suggestion))
    return found

# --- Streamlit Page Functions ---

def run_about_page():
    """The 'Home' page of the app."""
    st.title("Welcome to the AI Accessibility Toolkit üöÄ")
    st.subheader("Final project for the AI for Software Engineering course.")
    st.markdown("""
    This website is a collection of AI-powered tools designed to help solve real-world problems
    for people with disabilities, aligning with **UN Global Goals 3, 4, and 10**.

    Each tool on the left showcases a different AI concept from your course:

    * **Cognitive Simplifier**: Shows **NLP (Week 2)** using **Hugging Face (Week 5)**.
    * **Image Inspector**: Shows **Computer Vision (Week 2)** using **Keras/TF (Week 5)**.
    * **Inclusive Language Scanner**: Shows **NLP (Week 2)** and **Ethical AI (Week 6)**.

    Click a tool on the left sidebar to get started!
    """)

def run_simplifier():
    """Page 1: NLP Text Summarizer (for cognitive load)"""
    st.title("üß† Cognitive Simplifier")
    st.markdown("**(UN Goal 4: Quality Education)**")
    st.info("This tool helps users with cognitive disabilities by summarizing complex text into key points. It uses a **Hugging Face T5-Small** model.")

    st.header("Paste your text here:")
    text_input = st.text_area("Input Text", height=250, placeholder="Paste a long article, email, or document here...")

    if st.button("Simplify Text"):
        if text_input:
            with st.spinner("AI is thinking... This may take a moment on first run!"):
                # --- THIS IS A WORKING AI MODEL ---
                summary_text = summarize_text(text_input)
                st.header("AI-Generated Summary")
                st.success(summary_text)
        else:
            st.warning("Please paste some text to simplify.")

def run_image_inspector():
    """Page 2: CV Image Describer (for blind/low-vision)"""
    st.title("üëÅÔ∏è Image Inspector")
    st.markdown("**(UN Goal 10: Reduced Inequalities)**")
    st.info("This tool helps blind or low-vision users by describing images. It uses the **Keras/TensorFlow MobileNetV2** model.")

    uploaded_file = st.file_uploader("Upload an image...", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        st.image(uploaded_file, caption="Uploaded Image", use_column_width=True)

        with st.spinner("AI is inspecting the image..."):
            # --- THIS IS A WORKING AI MODEL ---
            predictions = get_image_predictions(uploaded_file)

            st.header("What the AI sees:")

            accessibility_concerns = []
            for (obj_id, label, prob) in predictions:
                st.write(f"* Found: **{label.replace('_', ' ')}** (Confidence: {prob*100:.2f}%)")
                # Check for accessibility barriers
                if label in ['stairs', 'stairway', 'step']:
                    accessibility_concerns.append(f"**Warning:** Detected '{label}', which is a barrier for wheelchair users.")

            if accessibility_concerns:
                st.header("Accessibility Concerns:")
                for concern in accessibility_concerns:
                    st.warning(concern)

            st.subheader("Ethical Consideration (Week 6):")
            st.warning("""
            This model was trained on **ImageNet**. It is **BIASED**. It will be bad at identifying
            'white cane' or 'wheelchair', as those were not common in its training data. A real-world
            project would fine-tune this on a better dataset.
            """)

def run_language_scanner():
    """Page 3: NLP Ethical AI Scanner (for inclusive language)"""
    st.title("ü§ù Inclusive Language Scanner")
    st.markdown("**(UN Goal 10: Reduced Inequalities & Goal 5: Gender Equality)**")
    st.info("This tool (for **Ethics, Week 6**) checks text for non-inclusive or ableist language and suggests better alternatives.")

    st.header("Paste your text here:")
    text_input = st.text_area("Input Text", height=250, placeholder="Paste a job description, email, or blog post here...")

    if st.button("Scan Text"):
        if text_input:
            # --- THIS IS A WORKING AI MODEL ---
            with st.spinner("AI is scanning..."):
                results = scan_inclusive_language(text_input)

                if not results:
                    st.success("Looks good! The AI found no problematic terms.")
                else:
                    st.error(f"The AI found {len(results)} potential issue(s):")
                    for (term, suggestion) in results:
                        st.warning(f"**Term:** \"{term}\"")
                        st.info(f"**Suggestion:** {suggestion}")
        else:
            st.warning("Please paste some text to scan.")

# --- Main App Structure ---
def main():
    # Set the page title and icon
    st.set_page_config(page_title="AI Accessibility Toolkit", page_icon="‚ôø")

    # --- Sidebar Navigation ---
    st.sidebar.title("AI Toolkit Navigation")
    st.sidebar.info("This is the main navigation for your Streamlit website.")

    # Define the pages in your app
    page_options = {
        "About this Project": run_about_page,
        "Cognitive Simplifier (NLP)": run_simplifier,
        "Image Inspector (CV)": run_image_inspector,
        "Inclusive Language Scanner (Ethics)": run_language_scanner,
    }

    # Create the radio button navigation
    page_selection = st.sidebar.radio("Choose a Tool:", list(page_options.keys()))

    # Run the function for the selected page
    # This is what makes the multi-page app work
    page_options[page_selection]()

    st.sidebar.markdown("---")
    st.sidebar.markdown("Built by a student in the **AI for Software Engineering** course.")

# This is the standard entry point for a Python script
if __name__ == "__main__":
    main()
